---
title: '在Windows下用Chatbox和Ollama部署DeepSeek-R1:14b'
author: 'J.sky'
time: '2025-02-03T04:51:50.768Z'
tag: 'AI,DeepSeek'
description: '博在本地部署大模型的过程中，我曾尝试在Windows Docker下安装Open WebUI。然而，这个过程并不顺利。Docker的配置、模型的加载以及与GPU的适配等问题，让我遇到了不少坑。经过一番折腾后，我意识到，或许需要一种更简洁、更高效的方式来实现本地部署。于是，我转向了Chatbox和Ollama的组合。'
---

## 为什么选择Chatbox + Ollama

在本地部署大模型的过程中，我曾尝试在Windows Docker下安装Open WebUI。然而，这个过程并不顺利。Docker的配置、模型的加载以及与GPU的适配等问题，让我遇到了不少坑。经过一番折腾后，我意识到，或许需要一种更简洁、更高效的方式来实现本地部署。于是，我转向了Chatbox和Ollama的组合。

### Ollama的安装与配置

访问Ollama的官方网站：[Download Ollama on Windows](https://ollama.com/download)，下载适用于Windows的安装程序。

![Ollama](https://www.suiyan.cc/assets/images/2025/d1.png)


安装完成后，在命令提示符或PowerShell中输入以下命令验证安装是否成功：

    ollama --version

如果显示版本号，说明Ollama已成功安装。指定安装目录与修改模型下载目录为了避免模型文件占用过多C盘空间，我们可以指定Ollama的安装目录和模型下载目录。通过设置环境变量 OLLAMA_MODELS,将模型文件存放在其他磁盘分区。例如，将模型文件存放在D盘的 ollama_models  目录下，可以在系统的环境变量设置中添加如下变量：

![Ollama](https://www.suiyan.cc/assets/images/2025/d5.png)


### 下载并运行DeepSeek R1 14B模型

在命令提示符或PowerShell中输入以下命令，下载DeepSeek R1 14B模型：

    ollama run deepseek-r1:14b


下载可能会很慢，最好放一边先干点别的事。下载完成后，模型会自动运行，

![Ollama](https://www.suiyan.cc/assets/images/2025/d3.png)

当看到上边的命令行的时候，就表明可以开始和deepseek大模型进行交互。



## Ollama 常用命令

基本命令

•   ollama   显示 Ollama 的帮助信息，列出所有可用的命令及其用法。

常用命令

•   serve   启动 Ollama 服务。这是运行 Ollama 的主要命令，用于启动本地服务，以便与模型进行交互。

•   create   根据指定的 Modelfile 创建一个模型。Modelfile 是一个配置文件，定义了模型的结构和参数。

•   show   显示指定模型的详细信息，包括模型的版本、大小、依赖关系等。•   run   运行一个模型。例如，  ollama run deepseek-r1:1.5b   会启动指定版本的 DeepSeek R1 模型。

•   stop   停止一个正在运行的模型。如果需要关闭某个模型，可以使用此命令。

•   pull   从模型仓库中拉取（下载）一个模型。例如，  ollama pull deepseek-r1:1.5b   会从远程仓库下载指定版本的模型。

•   push   将本地模型推送到模型仓库。这通常用于将自定义模型上传到远程仓库，以便共享或备份。

•   list   列出所有已安装的模型。此命令可以帮助你查看本地已下载和安装的模型列表。

•   ps   列出所有正在运行的模型。此命令可以帮助你查看当前正在运行的模型及其状态。

•   cp   复制一个模型。可以将一个已安装的模型复制到另一个位置或重命名。

•   rm   删除一个模型。如果不再需要某个模型，可以使用此命令将其从本地删除。

•   help   获取关于某个命令的帮助信息。例如，  ollama help run   会显示   run   命令的详细用法和参数说明。



## 安装Chatbox并配置本地模型

Chatbox是一个可视化界面工具，可以让我们更便捷地与模型交互。下载与安装访问 [Chatbox 官方免费下载](https://chatboxai.app/zh)，下载适用于Windows的版本。

配置本地模型安装完成后，打开Chatbox，进入设置页面：

![Ollama](https://www.suiyan.cc/assets/images/2025/d2.png)


• API类型：选择“OLLAMA API”。

• 接口地址：填写  http://localhost:11434  。

• 模型名称：填写  deepseek-r1:14b  ，确保与之前下载的模型版本一致。

完成配置后，就可以在Chatbox中与DeepSeek R1 14B模型进行对话了。

![Ollama](https://www.suiyan.cc/assets/images/2025/d4.png)


测试与总结

经过上述步骤，成功的在Windows环境下使用Chatbox和Ollama部署了DeepSeek R1 14B模型。在测试过程中，模型的响应速度和准确性都令人满意。比起使用docker折腾webUI要简单得多。
